---
title: "modeling2.Rmd"
author: "Francisco Javier Raya"
date: "3/23/2021"
output: html_document
---

```{r cars}

library(knitr)
library(caret)

test_table <- readRDS("testSet.RDS")

characters.non.ASCII <- grep("characters.unlist", iconv(test_table$feature, "latin1", "ASCII", sub="characters.unlist"))
noAscii <- test_table$feature[characters.non.ASCII]
test_table <- test_table[!test_table$feature %in% noAscii]

saveRDS(test_table, "testSet.RDS")

library(data.table)
gram4Model <- readRDS("gram4.RDS")
gram3Model <- readRDS("gram3.RDS")
gram2Model <- readRDS("gram2.RDS")
gram1Model <- readRDS("gram1.RDS")


gram1Model$'0'<-NULL
gram1Model$word <- NULL





get_no_exist_ngram_from_prefix <- function(data, unigram) {
    no_in_trigram <- unigram[!(unigram$feature %in% data$word), ]$feature
    return(no_in_trigram)
}



addDiscount <- function(data) {
  data$discount = rep(1, nrow(data))
  for(i in 5:2) {
      r <- i
      rPlus1 <- r + 1
      
      Nr <- nrow(data[frequency.x == r])
      NrPlus1 <- nrow(data[frequency.x == rPlus1])

      d <- min(1, (rPlus1 / r) * (NrPlus1 / Nr)) # assumption: 0 < d < 1
      
      # the beauty of "data.table"!
      data[frequency.x == r, discount := d]
  }
  # Calculate the remaining probability (thanks to discounting...).
  return (data)
}







models <- list(addDiscount(gram1Model[feature != '']), addDiscount(gram2Model[feature != '']), addDiscount(gram3Model[feature != '']), addDiscount(gram4Model[feature != '']))


saveRDS(models, "baseline.RDS")


#filter by profanity


```

```{r}



#coverage with 99% of words

wordCoverage <- function(percent, data) {
  ratio<-cumsum(data$frequency.x)/sum(data$frequency.x)
  return (which(ratio>=percent)[1])
}

models <- readRDS("baseline.RDS")
index <- wordCoverage(0.99, models[[1]])


models[[1]] <- models[[1]][1:index]


models[[2]] <- models[[2]][word %in% models[[1]]$feature]
models[[3]] <- models[[3]][word %in% models[[1]]$feature]

models[[4]] <- models[[4]][word %in% models[[1]]$feature]





saveRDS(models, "word99Reduction.RDS")


```









```{r}

models <- readRDS("baseline.RDS")
index <- wordCoverage(0.95, models[[1]])
models[[1]] <- models[[1]][1:index]


models[[2]] <- models[[2]][word %in% models[[1]]$feature]
models[[3]] <- models[[3]][word %in% models[[1]]$feature]

models[[4]] <- models[[4]][word %in% models[[1]]$feature]
saveRDS(models, "word95Reduction.RDS")


test_table <- readRDS("testSet.RDS")

```


```{r}

models <- readRDS("baseline.RDS")
index <- wordCoverage(0.90, models[[1]])
models[[1]] <- models[[1]][1:index]


models[[2]] <- models[[2]][word %in% models[[1]]$feature]
models[[3]] <- models[[3]][word %in% models[[1]]$feature]

models[[4]] <- models[[4]][word %in% models[[1]]$feature]
saveRDS(models, "word90Reduction.RDS")


test_table <- readRDS("testSet.RDS")

```




```{r}

models <- readRDS("baseline.RDS")
index <- wordCoverage(0.50, models[[1]])
models[[1]] <- models[[1]][1:index]


models[[2]] <- models[[2]][word %in% models[[1]]$feature]
models[[3]] <- models[[3]][word %in% models[[1]]$feature]

models[[4]] <- models[[4]][word %in% models[[1]]$feature]
saveRDS(models, "word50Reduction.RDS")


test_table <- readRDS("testSet.RDS")

```





```{r}

get_ngram_from_prefix <- function(prefix) {
  ngram_array <- unlist(strsplit(prefix, "_"))
  ngram_length <- length(ngram_array)
  if (ngram_length > 3) {
    prefix <- paste(ngram_array[(ngram_length-2):ngram_length],collapse= "_")
    ngram_length <- length(ngram_array[(ngram_length-2):ngram_length])
  }
  
  model <- models[[(ngram_length + 1)]]
  return (model[feature==prefix])
}



get_beta_table <- function(data, prefix) {
  if (nrow(data) > 0) return (data[, .(beta=calc_beta(frequency.x, discount)), by=feature])
  return (data.table(feature=c(prefix), beta=c(1)))
}




calc_beta <- function(frequency, discount){
    all_freq = sum(frequency)
    return(1-sum((discount*frequency)/all_freq))
}


construct_observed_grams_probabilites <- function(obs_grams) {
  all_freq <- sum(obs_grams$frequency.x)
  obs_grams$prob <- (obs_grams$frequency.x * obs_grams$discount) / all_freq
  return (obs_grams)
} 


get_new_prefix <- function(prefix) {
  newPrefix <- unlist(strsplit(prefix, "_"))
  newPrefix <- newPrefix[2:length(newPrefix)]
  return (paste(newPrefix, collapse="_"))
}

prediction <- function(prefix) {
  ngram_array <- unlist(strsplit(prefix, "_"))
  ngram_length <- length(ngram_array)
  if (ngram_length < 3) return (NULL)
  prefix <- paste(ngram_array[(length(ngram_array) - 2):length(ngram_array)], collapse="_")
  observed_4_grams <- get_ngram_from_prefix(prefix)
  observed_4_grams_probs <- construct_observed_grams_probabilites(observed_4_grams)
  
  beta_4 <- get_beta_table(observed_4_grams_probs, prefix) 
  
  observed_words <- observed_4_grams_probs$word
  unobs_4 <- c()
  if (length(observed_words) > 0) { unobs_4 <-models[[1]][!feature %in% observed_words]$feature }
  
  newPrefix <- get_new_prefix(prefix)
  
  observed_3_grams <- get_ngram_from_prefix(newPrefix)
  if (length(unobs_4) > 0) { observed_3_grams <- observed_3_grams[word %in% unobs_4] }
  observed_3_grams_probs <- construct_observed_grams_probabilites(observed_3_grams)
  
  observed_words <- append(observed_words, observed_3_grams_probs$word)
  
  all_3_probs <- sum(observed_3_grams_probs$prob)
 
  to_4_gram <- observed_3_grams_probs
  to_4_gram$feature <- prefix
  to_4_gram$prob <- (beta_4[feature == prefix]$beta / all_3_probs) * to_4_gram$prob
  
  beta_3 <- get_beta_table(observed_3_grams_probs, newPrefix)
  
  unobs_3 <- c()
  if (length(observed_words) > 0) { unobs_3 <- models[[1]][!feature %in% observed_words]$feature }
  
  oldPrefix <- newPrefix
  newPrefix <- get_new_prefix(newPrefix)
  observed_2_grams <- get_ngram_from_prefix(newPrefix)
  if (length(unobs_3) > 0) { observed_2_grams <- observed_2_grams[word %in% unobs_3] }
  observed_2_grams_probs <- construct_observed_grams_probabilites(observed_2_grams)
  
  observed_words <- append(observed_words, observed_2_grams_probs$word)
  
  all_2_probs <- sum(observed_2_grams_probs$prob)
  
  to_3_gram <- observed_2_grams_probs
  to_3_gram$feature <- prefix
  to_3_gram$prob <- (beta_3[feature == oldPrefix]$beta / all_2_probs) * to_3_gram$prob
  beta_2 <- get_beta_table(observed_2_grams_probs, newPrefix)
  
  unobs_2 <- c()
  if (length(observed_words) > 0) { unobs_2 <- models[[1]][!feature %in% observed_words]$feature }
  
  final_gram <- models[[1]]
  if (length(unobs_2) > 0) { final_gram <- final_gram[feature %in% unobs_2] }
  final_gram <- construct_observed_grams_probabilites(final_gram)
  
  all_1_probs <- sum(final_gram$prob)
  
  to_2_gram <- final_gram
  to_2_gram$word <- final_gram$feature
  to_2_gram$feature <- prefix
  to_2_gram$prob <- (beta_2[feature == newPrefix]$beta / all_1_probs) * to_2_gram$prob
  to_2_gram <- to_2_gram[order(-to_2_gram$prob), ]

  result <- rbind(observed_4_grams_probs[order(-observed_4_grams_probs$prob), ], to_4_gram[order(-to_4_gram$prob), ], 
                to_3_gram[order(-to_4_gram$prob), ], to_2_gram)
  
  
  return (result[order(-result$prob)][1:3])
}



evaluation <- function(data) {
  hit <- 0
  n_ej <- nrow(data)
  print (paste("num ejemplos: ", n_ej))
  for (i in 1:n_ej) {
    words <- prediction(data[i]$feature)

    if (data[i]$word %in% words$word) {
      print("predictions...")
      print(words$word)
      print("test...")
      print(data[i]$word)
      print("=====================================================")
      hit <- hit  + 1
    }
    if ((i %% 10) == 0) print (paste("Procesados ",i, "...", hit, " hits."))
  }
  acc <- (hit / n_ej)
}


set.seed(1234)
subset_test_table <- test_table[sample(1:nrow(test_table), 10000, replace = FALSE)]

evaluation(subset_test_table)

```